{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNets in TensorFlow!\n",
    "\n",
    "In this part of this assignment, we will work with TensorFlow to write a convolutional neural network!\n",
    "\n",
    "Credits to CS231N Assignment 2 (http://cs231n.github.io/assignments2018/assignment2/)\n",
    "\n",
    "### 1. Look at this code and understand it!\n",
    "\n",
    "This is a very simple 2-layer convnet. Understanding this code will help you with the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def simple_model(X,y):\n",
    "    # define our weights (e.g. init_two_layer_convnet)\n",
    "    \n",
    "    # setup variables\n",
    "    Wconv1 = tf.get_variable(\"Wconv1\", shape=[7, 7, 3, 32])\n",
    "    bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "    W1 = tf.get_variable(\"W1\", shape=[5408, 10])\n",
    "    b1 = tf.get_variable(\"b1\", shape=[10])\n",
    "\n",
    "    # define our graph (e.g. two_layer_convnet)\n",
    "    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    h1_flat = tf.reshape(h1,[-1,5408])\n",
    "    y_out = tf.matmul(h1_flat,W1) + b1\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a specific model!\n",
    "\n",
    "Using the code provided above as guidance, and using TensorFlow documentation, specify a model with the following architecture:\n",
    "\n",
    "1. 7x7 Convolutional Layer with 32 filters and stride of 1\n",
    "\n",
    "2. ReLU Activation Layer\n",
    "\n",
    "3. Spatial Batch Normalization Layer (trainable parameters, with scale and centering)\n",
    "\n",
    "4. 2x2 Max Pooling layer with a stride of 2\n",
    "\n",
    "5. Affine layer with 1024 output units\n",
    "\n",
    "6. ReLU Activation Layer\n",
    "\n",
    "7. Affine layer from 1024 input units to 10 outputs\n",
    "\n",
    "Hint: some of this documentation will help!\n",
    "\n",
    "Layers, Activations, Loss functions : https://www.tensorflow.org/api_guides/python/nn\n",
    "\n",
    "BatchNorm: https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# define our input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "def complex_model(X, y):\n",
    "    Wconv = tf.get_variable(\"Wconv\", shape=[7, 7, 3, 32])\n",
    "    bconv = tf.get_variable(\"bconv\", shape=[32])\n",
    "    Waffine1 = tf.get_variable(\"Waffine1\", shape=[5408, 1024])\n",
    "    baffine1 = tf.get_variable(\"baffine1\", shape=[1024])\n",
    "    Waffine2 = tf.get_variable(\"Waffine2\", shape=[1024, 10])\n",
    "    baffine2 = tf.get_variable(\"baffine2\", shape=[10])\n",
    "    \n",
    "    a1 = tf.nn.conv2d(X, Wconv, strides=[1, 1, 1, 1], padding='VALID') + bconv\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    batchnorm = tf.nn.batch_normalization(h1)\n",
    "    pool1act = tf.nn.max_pool(batchnorm, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    flatten1 = tf.reshape(pool1act, [-1, 5408])\n",
    "    affine1act = tf.matmul(flatten1, Waffine1) + baffine1\n",
    "    relu2act = tf.nn.relu(affine1act)\n",
    "    y_out = tf.matmul(relu2act, Waffine2) + baffine2\n",
    "    return y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run your model!\n",
    "\n",
    "Run your model using a `tf.Session()` and `feed_dict` on some data! You can choose whichever dataset you want, but if you want an easily-usable dataset, check out this MNIST tutorial which shows how to load in the data pretty easily:\n",
    "\n",
    "https://www.oreilly.com/learning/not-another-mnist-tutorial-with-tensorflow\n",
    "\n",
    "Have fun! Don't forget to create a training set and a testing set to evaluate your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tf.losses import sigmoid_cross_entropy\n",
    "from tf.metrics import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Did not implement batching\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "X, y = mnist.train.images, mnist.train.labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "result_train = complex_model(X_train, y_train)\n",
    "result_test = complex_model(X_test, y_test)\n",
    "accuracy_val = accuracy(result_test, y_test)\n",
    "\n",
    "loss = tf.sigmoid_cross_entropy(result_train, y_train)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(training_op, feed_dict={'X': X_train, 'y': y_train})\n",
    "    acc = sess.run(accuracy_val, feed_dict={'X': X_test, 'y': y_test})\n",
    "    print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
