{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: \n",
    "\n",
    "If you don't have graphviz installed: \n",
    "\n",
    "For Mac, run `brew install graphviz` in your terminal.\n",
    "For Windows/Linuz, run `pip install graphviz` in your terminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sajel/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/sajel/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "This notebook will walk through how to use decision trees with bagging and boosting methods in sklearn as well as introduce the bias variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the iris dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-0ac2669de9ab>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-0ac2669de9ab>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    iris =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "iris = # load iris dataset. CODE\n",
    "df = # load into dataframe. CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then add the species label to each datapoint using the encoding given in the dataset to understand what the overall dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-2c4389d24dc6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-2c4389d24dc6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df['species'] =\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df['species'] = # CODE\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataframe into training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "train = train.drop(['is_train'], axis = 1)\n",
    "test = test.drop(['is_train'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the labels and feature from both the training and test datasets and refactorize the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = # CODE\n",
    "train_labels =  # CODE\n",
    "test_features = # CODE \n",
    "test_labels = # CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a basic decision tree which minimizes entropy and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create decision tree that minimizes entropy \n",
    "# CODE \n",
    "\n",
    "#fit on to training data\n",
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize this decision tree by using graphviz. Visualizing a decision tree allows us to easily interpret how the predictions or classifications are made because each split is clearly defined.\n",
    "\n",
    "Notice how with each split the weighted entropy of the two branches is less than the entropy of the parent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-353f3e6dee4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dot_data = tree.export_graphviz(clf, out_file=None, \n\u001b[0m\u001b[1;32m      2\u001b[0m                          \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          special_characters=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graphviz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5b8d6f85ede1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graphviz' is not defined"
     ]
    }
   ],
   "source": [
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the training and validation accuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute training accuracy using score\n",
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute validation accuracy using score\n",
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use Grid Search to find a good set of hyperparameters which attempt to regualize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"min_samples_split\": [2, 10],\n",
    "              \"max_depth\": [None, 2, 5, 10],\n",
    "              \"min_samples_leaf\": [1, 5, 10],\n",
    "              \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "              }\n",
    "# use GridSearchCV\n",
    "# CODE HERE\n",
    "\n",
    "# fit gridsearch on training data and labels\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best decision tree from gridsearch\n",
    "best_tree = # CODE\n",
    "\n",
    "# fit best decision on training data and labels\n",
    "# CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to visualize the new tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5bd23af43dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dot_data = tree.export_graphviz(best_tree, out_file=None, \n\u001b[0m\u001b[1;32m      2\u001b[0m                          \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          special_characters=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_tree' is not defined"
     ]
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(best_tree, out_file=None, \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the difference between the validation and training accuracies is not as large as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use score to get best tree training accuracy\n",
    "# CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use score to get best tree validation accuracy\n",
    "# CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train a Random Forest Classifier on the same dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier minimizing entropy. set estimators to 100\n",
    "# CODE \n",
    "\n",
    "# fit classifier on training data \n",
    "# CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use score to get training accuracy\n",
    "# CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use score to get validation accuracy\n",
    "# CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an AdaBoost Classifier on the same dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tree = tree.DecisionTreeClassifier(max_depth=2, min_samples_leaf=3, criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize AdaBoostClassifier based on default tree\n",
    "# CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit boost classifier on training data\n",
    "# CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use score to get boost training accuracy\n",
    "# CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use score to get boost validation accuracy\n",
    "# CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions: \n",
    "\n",
    "1) In your own words, explain what a decision tree is.\n",
    "    \n",
    "    Answer here.\n",
    "    \n",
    "2) What does it mean to regularize a decision tree?\n",
    "\n",
    "    Answer here.\n",
    "    \n",
    "3) What are some ways you can regularize a decision tree?\n",
    "    \n",
    "    Answer here.\n",
    "\n",
    "4) Why do decision trees get higher training accuracy than testing accuracy?\n",
    "\n",
    "    Answer here.\n",
    "\n",
    "5) Why are the testing and training accuracy not so different from each other when we find the best decision tree (`best_tree`)?\n",
    "\n",
    "    Answer here.\n",
    "\n",
    "\n",
    "6) In your own words, explain how a random forest works and how regularization works in random forests.\n",
    "\n",
    "    Answer here.\n",
    "\n",
    "\n",
    "7) Explain in your own words and in detail what GridSearchCV does.\n",
    "    \n",
    "    Answer here.\n",
    "\n",
    "\n",
    "8) What does boosting do and why is it useful? Connect this back to what we did with the iris dataset. \n",
    "\n",
    "    Answer here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
